Tengo este código 'extractor.py'
"
import pandas as pd
import numpy as np
import os
import re
from datetime import datetime

# Configuración de rutas
PATHS = {
    'asistencia': 'data/asistencia',
    'calificaciones': 'data/calificaciones',
    'datos_demograficos': 'data/datos_demograficos'
}

# Listas de nombres para corrección de género
NOMBRES_FEMENINOS = [
    'María', 'Ana', 'Sofía', 'Lucía', 'Valentina', 'Camila', 'Ximena', 'Renata',
    'Daniela', 'Gabriela', 'Victoria', 'Isabella', 'Paula', 'Alejandra', 'Fernanda'
]

NOMBRES_MASCULINOS = [
    'Juan', 'Luis', 'Carlos', 'José', 'Miguel', 'Jorge', 'Diego', 'Manuel',
    'Pedro', 'Ricardo', 'Francisco', 'Andrés', 'Antonio', 'Rafael', 'Alejandro'
]

# Materias por semestre
materias_por_semestre = {
    2: [
        "Representación simbólica y angular del entorno",
        "Comunicación activa en inglés",
        "Relación entre compuestos orgánicos y el entorno",
        "Comunicación en los ámbitos escolar y profesional",
        "Emprendimiento e innovación",
        "Manejo de aplicaciones por medios digitales",
        "Desarrollo de pensamiento computacional",
        "Identificación de redes de computadoras",
        "Implementación de interfaces de programación"
    ],
    4: [
        "Análisis derivativo de funciones",
        "Comunicación productiva en inglés",
        "Interpretación de fenómenos físicos de la materia",
        "Desarrollo ciudadano",
        "Desarrollo ágil de sistemas",
        "Aplicación de protocolos de datos",
        "Aplicación de modelos ETL",
        "Análisis de tendencias en datos"
    ],
    6: [
        "Tratamiento de datos y azar",
        "Interpretación de normas de convivencia ambiental",
        "Filosofía",
        "Aplicación de modelos predictivos",
        "Presentación y análisis prescriptivo de los datos",
        "Análisis del lenguaje natural",
        "Gestión de rendimiento de los datos"
    ]
}

# =====================================================
# Funciones para cargar datos desde diferentes formatos
# =====================================================

def cargar_csv(ruta):
    return pd.read_csv(ruta, encoding='utf-8-sig')

def cargar_json(ruta):
    return pd.read_json(ruta, encoding='utf-8')

def cargar_xml(ruta):
    try:
        return pd.read_xml(ruta)
    except:
        # Manejo manual de XML si falla la carga estándar
        with open(ruta, 'r', encoding='utf-8') as f:
            xml_content = f.read()
        
        # Extraer registros
        registros = re.findall(r'<registro>(.*?)</registro>', xml_content, re.DOTALL)
        datos = []
        
        for reg in registros:
            fila = {}
            campos = re.findall(r'<([^>]+)>(.*?)</\1>', reg, re.DOTALL)
            for campo, valor in campos:
                fila[campo] = valor.strip()
            datos.append(fila)
        
        return pd.DataFrame(datos)

def cargar_dataset(tipo):
    """Carga todos los archivos de un dataset, elimina duplicados y maneja valores vacíos"""
    dfs = []
    for formato in ['csv', 'json', 'xml']:
        ruta = os.path.join(PATHS[tipo], f"{tipo}.{formato}")
        if os.path.exists(ruta):
            if formato == 'csv':
                df_temp = cargar_csv(ruta)
            elif formato == 'json':
                df_temp = cargar_json(ruta)
            elif formato == 'xml':
                df_temp = cargar_xml(ruta)
                
                # Corrección específica para nombres de columnas en XML
                if tipo == 'calificaciones':
                    # Revertir sanitización: guiones bajos a espacios
                    new_columns = {}
                    for col in df_temp.columns:
                        if col not in ['MATRICULA', 'SEMESTRE']:
                            new_columns[col] = col.replace('_', ' ')
                        else:
                            new_columns[col] = col
                    df_temp = df_temp.rename(columns=new_columns)
                
                elif tipo == 'asistencia':
                    # Remover guión bajo inicial y mantener formato de fecha
                    new_columns = {}
                    for col in df_temp.columns:
                        if col != 'MATRICULA':
                            new_columns[col] = col.lstrip('_')
                        else:
                            new_columns[col] = col
                    df_temp = df_temp.rename(columns=new_columns)
            
            # Manejar valores None y NaN
            df_temp = df_temp.fillna('')
            dfs.append(df_temp)
    
    if dfs:
        # Combinar todos los DataFrames
        df = pd.concat(dfs, ignore_index=True)
        
        # Eliminar duplicados
        df = df.drop_duplicates()
        
        # Eliminar filas completamente vacías
        df = df.dropna(how='all')
        
        return df
    return pd.DataFrame()

# =====================================================
# Funciones de corrección de datos (MANTENIDAS SIN CAMBIOS)
# =====================================================

def inferir_genero(nombre):
    """Infiere el género basado en listas de nombres"""
    nombre = str(nombre).strip()
    if nombre in NOMBRES_FEMENINOS:
        return 'F'
    elif nombre in NOMBRES_MASCULINOS:
        return 'M'
    return ''

def formatear_fecha(fecha_str):
    """Intenta convertir una cadena de fecha al formato dd/mm/YYYY"""
    if not fecha_str or fecha_str in ['None', 'nan', '']:
        return None
    
    # Limpiar caracteres no deseados (guiones bajos, espacios, etc.)
    fecha_limpia = re.sub(r'[^0-9/]', '', str(fecha_str))
    
    # Intentar parsear la fecha en diferentes formatos
    formatos_posibles = [
        '%d/%m/%Y',  # Formato esperado
        '%Y/%m/%d',  # Formato ISO
        '%m/%d/%Y',  # Formato americano
        '%d%m%Y',    # Sin separadores
        '%Y%m%d'     # Formato ISO sin separadores
    ]
    
    for formato in formatos_posibles:
        try:
            fecha_dt = datetime.strptime(fecha_limpia, formato)
            return fecha_dt.strftime('%d/%m/%Y')
        except ValueError:
            continue
    
    # Si ninguno funcionó, devolver la fecha limpia (podría no estar formateada)
    return fecha_limpia

def corregir_asistencias(df):
    """Correcciones para el dataset de asistencias"""
    # Identificar columnas de fechas (todas excepto MATRICULA)
    columnas_fecha = [col for col in df.columns if col != 'MATRICULA']
    
    # Convertir S/N a booleanos (True/False)
    for col in columnas_fecha:
        # Convertir a string y limpiar valores
        df[col] = df[col].astype(str).str.strip().str.upper()
        
        # Aplicar reglas de corrección
        df[col] = np.where(
            df[col].isin(['S', '1', 'TRUE', 'T']), 
            True, 
            np.where(
                df[col].isin(['N', '0', 'FALSE', 'F']),
                False,
                False  # Cualquier otro valor se considera ausente
            )
        )
    
    return df

def corregir_calificaciones(df_calif):
    """Correcciones para el dataset de calificaciones"""
    # Verificar y corregir columna SEMESTRE
    if 'SEMESTRE' not in df_calif.columns:
        df_calif['SEMESTRE'] = 2
    
    # Convertir SEMESTRE a numérico y manejar errores
    df_calif['SEMESTRE'] = pd.to_numeric(df_calif['SEMESTRE'], errors='coerce')
    # Rellenar valores faltantes con 2 y convertir a entero
    df_calif['SEMESTRE'] = df_calif['SEMESTRE'].fillna(2).astype(int)
    # Forzar semestres válidos (2,4,6)
    df_calif['SEMESTRE'] = df_calif['SEMESTRE'].apply(
        lambda x: x if x in {2, 4, 6} else 2
    )
    
    # Identificar columnas de materias
    materias_df = [col for col in df_calif.columns if col not in ['MATRICULA', 'SEMESTRE']]
    
    # 1. Convertir todas las materias a numérico
    for materia in materias_df:
        df_calif[materia] = pd.to_numeric(df_calif[materia], errors='coerce')
    
    # 2. Eliminar calificaciones de materias no correspondientes al semestre
    for idx, row in df_calif.iterrows():
        semestre = row['SEMESTRE']
        materias_validas = materias_por_semestre.get(semestre, [])
        
        for materia in materias_df:
            if materia not in materias_validas:
                df_calif.at[idx, materia] = np.nan
    
    # 3. Calcular promedios por alumno (solo materias válidas)
    promedios_alumno = {}
    for matricula, group in df_calif.groupby('MATRICULA'):
        # Obtener semestre del grupo (todos deberían ser iguales)
        semestre = group['SEMESTRE'].iloc[0]
        materias_validas = materias_por_semestre.get(semestre, [])
        
        # Filtrar solo materias válidas presentes en el DataFrame
        materias_calculo = [m for m in materias_validas if m in group.columns]
        valores_validos = group[materias_calculo].values.flatten()
        valores_validos = valores_validos[~np.isnan(valores_validos)]
        valores_validos = valores_validos[(valores_validos >= 1) & (valores_validos <= 100)]
        
        if len(valores_validos) > 0:
            promedios_alumno[matricula] = np.mean(valores_validos)
        else:
            promedios_alumno[matricula] = 70.0  # Valor predeterminado
    
    # 4. Reemplazar valores anormales en materias válidas
    def corregir_valor_materia(row, materia):
        valor = row[materia]
        # Solo corregir si es materia válida para el semestre
        semestre = row['SEMESTRE']
        materias_validas = materias_por_semestre.get(semestre, [])
        
        if materia not in materias_validas:
            return np.nan
        
        # Verificar si el valor es anormal
        if pd.isna(valor) or valor < 1 or valor > 100:
            return promedios_alumno[row['MATRICULA']]
        return valor
    
    for materia in materias_df:
        df_calif[materia] = df_calif.apply(
            lambda row: corregir_valor_materia(row, materia), 
            axis=1
        )
    
    return df_calif

def corregir_datos_demograficos(df_demo, df_calif):
    """Correcciones para el dataset demográfico"""
    # Obtener semestre de calificaciones
    df_demo = df_demo.merge(
        df_calif[['MATRICULA', 'SEMESTRE']], 
        on='MATRICULA', 
        how='left'
    )
    
    # 1. Corregir nombres vacíos
    # Si el nombre está vacío, usar 'Alumno' o 'Alumna' basado en el género
    df_demo['NOMBRE'] = df_demo.apply(
        lambda x: 'Alumna' if x['GENERO'] == 'F' else 'Alumno'
        if pd.isna(x['NOMBRE']) or x['NOMBRE'] == '' else x['NOMBRE'],
        axis=1
    )
    
    # 2. Corregir género vacío
    # Primero intentar inferir del nombre
    df_demo['GENERO_CORREGIDO'] = df_demo.apply(
        lambda x: inferir_genero(x['NOMBRE']) 
        if pd.isna(x['GENERO']) or x['GENERO'] == '' else x['GENERO'],
        axis=1
    )
    
    # Si aún está vacío, establecer 'M' como predeterminado
    df_demo['GENERO_CORREGIDO'] = df_demo['GENERO_CORREGIDO'].replace('', 'M')
    df_demo['GENERO_CORREGIDO'] = df_demo['GENERO_CORREGIDO'].fillna('M')
    
    # 3. Corregir fechas de nacimiento vacías o inválidas
    def corregir_fecha_nacimiento(row):
        fecha = str(row['FECHA_NACIMIENTO']).strip()
        if not fecha or fecha == 'None' or fecha == 'nan':
            semestre = row['SEMESTRE']
            if semestre == 2:
                return '01/01/2009'
            elif semestre == 4:
                return '01/01/2008'
            else:  # semestre 6
                return '01/01/2007'
        return fecha
    
    # Primero aplicar la corrección básica
    df_demo['FECHA_NACIMIENTO_CORREGIDA'] = df_demo.apply(
        corregir_fecha_nacimiento, 
        axis=1
    )
    
    # Luego formatear todas las fechas al formato dd/mm/YYYY
    df_demo['FECHA_NACIMIENTO_CORREGIDA'] = df_demo['FECHA_NACIMIENTO_CORREGIDA'].apply(formatear_fecha)
    
    # Para las fechas que aún no se pudieron formatear, usar valores predeterminados por semestre
    mascara_fecha_invalida = df_demo['FECHA_NACIMIENTO_CORREGIDA'].isna()
    df_demo.loc[mascara_fecha_invalida, 'FECHA_NACIMIENTO_CORREGIDA'] = df_demo[mascara_fecha_invalida].apply(
        lambda row: '01/01/2009' if row['SEMESTRE'] == 2 else
                   '01/01/2008' if row['SEMESTRE'] == 4 else
                   '01/01/2007',
        axis=1
    )
    
    # 4. Eliminar columna TITULO si existe
    if 'TITULO' in df_demo.columns:
        df_demo = df_demo.drop(columns=['TITULO'])
    
    # Seleccionar y renombrar columnas finales
    df_demo = df_demo[[
        'MATRICULA', 'NOMBRE', 'APELLIDO_PATERNO', 'APELLIDO_MATERNO', 
        'GENERO_CORREGIDO', 'FECHA_NACIMIENTO_CORREGIDA', 'NACIONALIDAD', 'SEMESTRE'
    ]].rename(columns={
        'GENERO_CORREGIDO': 'GENERO',
        'FECHA_NACIMIENTO_CORREGIDA': 'FECHA_NACIMIENTO'
    })
    
    return df_demo

# =====================================================
# Procesamiento principal
# =====================================================

def main():
    # Cargar todos los datasets
    print("Cargando datos de asistencias...")
    df_asistencias = cargar_dataset('asistencia')
    
    print("Cargando datos de calificaciones...")
    df_calificaciones = cargar_dataset('calificaciones')
    
    print("Cargando datos demográficos...")
    df_demograficos = cargar_dataset('datos_demograficos')
    
    # Aplicar correcciones
    print("Aplicando correcciones a asistencias...")
    df_asistencias_corregidas = corregir_asistencias(df_asistencias)
    
    print("Aplicando correcciones a calificaciones...")
    df_calificaciones_corregidas = corregir_calificaciones(df_calificaciones)
    
    print("Aplicando correcciones a datos demográficos...")
    df_demograficos_corregidos = corregir_datos_demograficos(
        df_demograficos, 
        df_calificaciones_corregidas
    )
    
    # Combinar todos los datos
    print("Combinando datasets...")
    # Primero combinar datos demográficos con calificaciones
    df_temp = pd.merge(
        df_demograficos_corregidos,
        df_calificaciones_corregidas,
        on=['MATRICULA', 'SEMESTRE'],
        how='inner'
    )
    
    # Luego combinar con asistencias
    df_final = pd.merge(
        df_temp,
        df_asistencias_corregidas,
        on='MATRICULA',
        how='inner'
    )
    
    # Eliminar posibles duplicados restantes
    df_final = df_final.drop_duplicates(subset='MATRICULA')
    
    # Guardar resultado consolidado
    os.makedirs('data/consolidado', exist_ok=True)
    ruta_final = 'data/consolidado/datos_consolidados.csv'
    df_final.to_csv(ruta_final, index=False, encoding='utf-8-sig')
    
    print("\nProceso completado exitosamente!")
    print(f"Datos consolidados guardados en: {ruta_final}")
    print(f"Total de registros procesados: {len(df_final)}")
    print(f"Total de columnas: {len(df_final.columns)}")
    print(f"Matrículas únicas: {df_final['MATRICULA'].nunique()}")

if __name__ == "__main__":
    main()
"
que trabaja con los archivos generados por los siguientes códigos
"
import pandas as pd
import numpy as np
import os
import re

# 1. Generar lista de matrículas desde 1001 hasta 1100
matriculas = list(range(1001, 1101))

# 2. Generar el rango de fechas de lunes a viernes
fechas = pd.date_range(
    start="2025-02-17",
    end="2025-07-04",
    freq="B"  # 'B' = business days (excluye sábados y domingos)
)
# Formatear como dd/mm/YYYY
fechas_str = fechas.strftime("%d/%m/%Y")

# 3. Crear DataFrame vacío con índices = matrículas y columnas = fechas
df = pd.DataFrame(
    index=matriculas,
    columns=fechas_str
)

# 4. Rellenar asistencias de forma aleatoria (“S” o “N”)
np.random.seed(42)  # para reproducibilidad
df[:] = np.random.choice(
    ["S", "N"],
    size=(len(matriculas), len(fechas_str)),
    p = [0.7, 0.3]
)

# 5. Preparar para exportar: convertir el índice en columna “MATRICULA”
df.index.name = "MATRICULA"
df.reset_index(inplace=True)

# --- Nuevas modificaciones solicitadas ---

# A. Borrar un 1% de las asistencias (convertirlas a NaN)
num_filas, num_columnas = df.shape
total_celdas = num_filas * (num_columnas - 1)  # Excluye columna MATRICULA
num_celdas_borrar = int(total_celdas * 0.01)   # 1% del total

if num_celdas_borrar > 0:
    # Generar coordenadas aleatorias sin repetición
    filas_aleatorias = np.random.choice(num_filas, size=num_celdas_borrar, replace=False)
    # Columnas: excluyendo la primera (MATRICULA)
    columnas_aleatorias = np.random.choice(range(1, num_columnas), size=num_celdas_borrar, replace=False)
    
    for i in range(num_celdas_borrar):
        fila = filas_aleatorias[i]
        col = columnas_aleatorias[i]
        df.iat[fila, col] = np.nan

# Convertir todos los NaN a string vacío
df = df.fillna("")

# B. Renombrar columnas de fecha para formato válido (reemplazar / por -)
nuevas_columnas = ['MATRICULA'] + [fecha.replace('/', '-') for fecha in fechas_str]
df.columns = nuevas_columnas

# C. Crear directorio principal si no existe
os.makedirs("data/asistencia", exist_ok=True)

# D. Guardar en tres formatos diferentes (muestreo aleatorio)
# Mezclar el DataFrame
df_muestreo = df.sample(frac=1, random_state=42).reset_index(drop=True)
total_filas = len(df_muestreo)

# Dividir en tres partes aproximadamente iguales
tam_parte = total_filas // 3
partes = [
    df_muestreo.iloc[:tam_parte],
    df_muestreo.iloc[tam_parte:2*tam_parte],
    df_muestreo.iloc[2*tam_parte:]
]

# Función para crear nombres XML válidos
def make_valid_xml_name(col_name: str) -> str:
    # Si empieza por dígito, anteponemos '_'
    if re.match(r'^[0-9]', col_name):
        return "_" + col_name
    return col_name

# Procesar solo el DataFrame para XML
df_xml = partes[1].copy()

# Aplicar solo a las columnas de fecha (dejamos "MATRICULA" igual)
new_cols = []
for c in df_xml.columns:
    if c == "MATRICULA":
        new_cols.append(c)
    else:
        new_cols.append(make_valid_xml_name(c))
df_xml.columns = new_cols

# Guardar cada parte en diferente formato
partes[0].to_csv(r"data/asistencia/asistencia.csv", index=False, encoding="utf-8")
df_xml.to_xml(r"data/asistencia/asistencia.xml", index=False)
partes[2].to_json(r"data/asistencia/asistencia.json", orient="records", indent=4)

print("Proceso completado:")
print(f"- CSV guardado en: data/asistencia/asistencia.csv")
print(f"- XML guardado en: data/asistencia/asistencia.xml")
print(f"- JSON guardado en: data/asistencia/asistencia.json")
"
"
import pandas as pd
import numpy as np
import os
import re
import random
import csv

# === Parte 1: Generar el archivo CSV original ===
materias_por_semestre = {
    2: [
        "Representación simbólica y angular del entorno",
        "Comunicación activa en inglés",
        "Relación entre compuestos orgánicos y el entorno",
        "Comunicación en los ámbitos escolar y profesional",
        "Emprendimiento e innovación",
        "Manejo de aplicaciones por medios digitales",
        "Desarrollo de pensamiento computacional",
        "Identificación de redes de computadoras",
        "Implementación de interfaces de programación"
    ],
    4: [
        "Análisis derivativo de funciones",
        "Comunicación productiva en inglés",
        "Interpretación de fenómenos físicos de la materia",
        "Desarrollo ciudadano",
        "Desarrollo ágil de sistemas",
        "Aplicación de protocolos de datos",
        "Aplicación de modelos ETL",
        "Análisis de tendencias en datos"
    ],
    6: [
        "Tratamiento de datos y azar",
        "Interpretación de normas de convivencia ambiental",
        "Filosofía",
        "Aplicación de modelos predictivos",
        "Presentación y análisis prescriptivo de los datos",
        "Análisis del lenguaje natural",
        "Gestión de rendimiento de los datos"
    ]
}

matriculas = [str(1001 + i) for i in range(100)]
semestres = [2, 4, 6]
datos = []

for matricula in matriculas:
    semestre = random.choice(semestres)
    registro = {'MATRICULA': matricula, 'SEMESTRE': semestre}
    
    for materia in materias_por_semestre[semestre]:
        registro[materia] = random.choices(
            population = [random.randint(0, 59), random.randint(60, 100)],
            weights = [0.1, 0.9],
            k = 1
        )[0]
    
    datos.append(registro)

todas_materias = []
for semestre in [2, 4, 6]:
    todas_materias.extend(materias_por_semestre[semestre])

# Crear directorio si no existe
os.makedirs("tmp", exist_ok=True)

# Escribir el archivo CSV original
with open(r'tmp\calificaciones.csv', 'w', newline='', encoding='utf-8-sig') as csvfile:
    campos = ['MATRICULA', 'SEMESTRE'] + todas_materias
    writer = csv.DictWriter(csvfile, fieldnames=campos)
    writer.writeheader()
    for registro in datos:
        writer.writerow(registro)

print("Archivo original 'calificaciones.csv' generado exitosamente!")

# === Parte 2: Cargar y ensuciar internamente ===

# Cargar el CSV generado en un DataFrame
df = pd.read_csv(r'tmp\calificaciones.csv', encoding='utf-8-sig')

# Identificar columnas de materias (todas excepto MATRICULA y SEMESTRE)
materias_cols = [col for col in df.columns if col not in ['MATRICULA', 'SEMESTRE']]

# Calcular número de registros a ensuciar (1%)
num_registros = len(df)
num_ensuciar = max(1, int(num_registros * 0.01))  # Al menos 1 registro

# Seleccionar registros aleatorios para ensuciar
registros_ensuciar = np.random.choice(df.index, size=num_ensuciar, replace=False)

# Procesar cada registro seleccionado
for idx in registros_ensuciar:
    # Seleccionar aproximadamente el 1% de las materias para modificar
    num_materias_modificar = max(1, int(len(materias_cols) * 0.01))
    materias_modificar = random.sample(materias_cols, num_materias_modificar)
    
    for materia in materias_modificar:
        # Seleccionar aleatoriamente una operación de ensuciado
        operacion = random.choice(['multiplicar', 'dividir'])
        
        if operacion == 'multiplicar':
            # Multiplicar por 100
            df.at[idx, materia] = df.at[idx, materia] * 100
        elif operacion == 'dividir':
            # Dividir entre 100
            df.at[idx, materia] = df.at[idx, materia] / 100

# === Parte 3: Muestreo aleatorio y exportación múltiple ===

# Mezclar el DataFrame ensuciado
df_muestreo = df.sample(frac=1, random_state=42).reset_index(drop=True)
total_filas = len(df_muestreo)

# Dividir en tres partes aproximadamente iguales
tam_parte = total_filas // 3
partes = [
    df_muestreo.iloc[:tam_parte],
    df_muestreo.iloc[tam_parte:2*tam_parte],
    df_muestreo.iloc[2*tam_parte:]
]

# Crear directorios necesarios
os.makedirs("data/calificaciones", exist_ok=True)

# Función para sanitizar nombres XML
def sanitize_xml_name(name):
    # Reemplazar caracteres especiales y espacios por guiones bajos
    sanitized = re.sub(r'[^\w]', '_', name)
    # Asegurar que no empiece con número
    if re.match(r'^\d', sanitized):
        sanitized = 'm_' + sanitized
    return sanitized

# 1. Exportar primera parte como CSV
partes[0].to_csv(r'data/calificaciones/calificaciones.csv', index=False, encoding='utf-8-sig')

# 2. Exportar segunda parte como JSON
partes[1].to_json(r'data/calificaciones/calificaciones.json', orient='records', indent=4, force_ascii=False)

# 3. Exportar tercera parte como XML (con sanitización de nombres)
df_xml = partes[2].copy()

# Sanitizar nombres de columnas para XML
nuevos_nombres = {col: sanitize_xml_name(col) for col in df_xml.columns}
df_xml.rename(columns=nuevos_nombres, inplace=True)

# Construir XML manualmente para mayor control
xml_content = '<?xml version="1.0" encoding="UTF-8"?>\n<calificaciones>\n'

for _, row in df_xml.iterrows():
    xml_content += '  <registro>\n'
    for col_name, value in row.items():
        xml_content += f'    <{col_name}>'
        
        # Manejar diferentes tipos de datos
        if pd.isna(value):
            xml_content += ''
        elif isinstance(value, (int, float)):
            xml_content += str(value)
        else:
            # Escapar caracteres especiales para XML
            if isinstance(value, str):
                value = value.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            xml_content += str(value)
        
        xml_content += f'</{col_name}>\n'
    xml_content += '  </registro>\n'

xml_content += '</calificaciones>'

# Guardar XML con codificación UTF-8
with open(r'data/calificaciones/calificaciones.xml', 'w', encoding='utf-8') as xml_file:
    xml_file.write(xml_content)

print("Proceso completado exitosamente!")
print("Archivos generados:")
print(f"- CSV original: csv{os.sep}calificaciones.csv")
print(f"- Muestra CSV: data{os.sep}calificaciones{os.sep}calificaciones.csv")
print(f"- Muestra JSON: data{os.sep}calificaciones{os.sep}calificaciones.json")
print(f"- Muestra XML: data{os.sep}calificaciones{os.sep}calificaciones.xml")
"
"
import pandas as pd
import numpy as np
import os
import re
import random

# === Configuración inicial ===
# Crear directorios necesarios
os.makedirs("tmp", exist_ok=True)
os.makedirs("data/datos_demograficos", exist_ok=True)

# === Leer archivo base ===
# Leer el archivo calificaciones.csv para obtener matrículas y semestres
df_base = pd.read_csv(r'tmp/calificaciones.csv', encoding='utf-8-sig')
# Conservar solo las columnas necesarias
df_base = df_base[['MATRICULA', 'SEMESTRE']]

# === Configuración para datos demográficos ===
nombres_femeninos = [
    'María', 'Ana', 'Sofía', 'Lucía', 'Valentina', 'Camila', 'Ximena', 'Renata',
    'Daniela', 'Gabriela', 'Victoria', 'Isabella', 'Paula', 'Alejandra', 'Fernanda'
]

nombres_masculinos = [
    'Juan', 'Luis', 'Carlos', 'José', 'Miguel', 'Jorge', 'Diego', 'Manuel',
    'Pedro', 'Ricardo', 'Francisco', 'Andrés', 'Antonio', 'Rafael', 'Alejandro'
]

apellidos = [
    'García', 'Rodríguez', 'Martínez', 'Hernández', 'López', 'Pérez', 'González',
    'Sánchez', 'Ramírez', 'Torres', 'Flores', 'Díaz', 'Vázquez', 'Castro', 'Ruiz',
    'Jiménez', 'Mendoza', 'Álvarez', 'Romero', 'Navarro', 'Morales', 'Ortega'
]

paises = {
    'MX': 'Mexicana',
    'US': 'Estadounidense',
    'ES': 'Española',
    'CO': 'Colombiana',
    'AR': 'Argentina',
    'CL': 'Chilena',
    'PE': 'Peruana',
    'EC': 'Ecuatoriana',
    'GT': 'Guatemalteca',
    'CU': 'Cubana'
}

# === Generar datos demográficos ===
datos = []

for _, row in df_base.iterrows():
    matricula = row['MATRICULA']
    semestre = row['SEMESTRE']
    
    # Determinar género y nombre
    genero = random.choice(['F', 'M'])
    if genero == 'F':
        nombre = random.choice(nombres_femeninos)
    else:
        nombre = random.choice(nombres_masculinos)
    
    # Generar apellidos
    apellido_paterno = random.choice(apellidos)
    apellido_materno = random.choice(apellidos)
    
    # Calcular fecha de nacimiento según semestre
    if semestre == 2:
        año_nacimiento = 2009
    elif semestre == 4:
        año_nacimiento = 2008
    else:  # semestre 6
        año_nacimiento = 2007
    
    # Generar mes y día aleatorios
    mes_nacimiento = random.randint(1, 12)
    # Determinar días máximos por mes
    if mes_nacimiento == 2:
        max_dias = 28
    elif mes_nacimiento in [4, 6, 9, 11]:
        max_dias = 30
    else:
        max_dias = 31
    
    dia_nacimiento = random.randint(1, max_dias)
    fecha_nacimiento = f"{dia_nacimiento:02d}/{mes_nacimiento:02d}/{año_nacimiento}"
    
    # Seleccionar nacionalidad
    nacionalidad = random.choice(list(paises.values()))
    
    # Crear registro
    registro = {
        'MATRICULA': matricula,
        'NOMBRE': nombre,
        'APELLIDO_PATERNO': apellido_paterno,
        'APELLIDO_MATERNO': apellido_materno,
        'GENERO': genero,
        'FECHA_NACIMIENTO': fecha_nacimiento,
        'NACIONALIDAD': nacionalidad
    }
    
    datos.append(registro)

# Crear DataFrame
df = pd.DataFrame(datos)

# === Ensuciar datos ===
# Campos a ensuciar
campos_ensuciar = ['NOMBRE', 'GENERO', 'FECHA_NACIMIENTO']

# Calcular número de registros a ensuciar (30%)
num_registros = len(df)
num_ensuciar = max(1, int(num_registros * 0.30))

# Seleccionar registros aleatorios para ensuciar
registros_ensuciar = np.random.choice(df.index, size=num_ensuciar, replace=False)

# Procesar cada registro seleccionado
for idx in registros_ensuciar:
    # Seleccionar aleatoriamente 1-3 campos para borrar
    num_campos_borrar = random.randint(1, 3)
    campos_borrar = random.sample(campos_ensuciar, num_campos_borrar)
    
    for campo in campos_borrar:
        df.at[idx, campo] = ''

# === Exportar a múltiples formatos ===
# Función para sanitizar nombres XML
def sanitize_xml_name(name):
    # Reemplazar caracteres especiales por guiones bajos
    sanitized = re.sub(r'[^\w]', '_', name)
    # Asegurar que no empiece con número
    if re.match(r'^\d', sanitized):
        sanitized = 'col_' + sanitized
    return sanitized

# 1. Exportar como CSV
df.to_csv(r'data/datos_demograficos/datos_demograficos.csv', index=False, encoding='utf-8-sig')

# 2. Exportar como JSON
df.to_json(r'data/datos_demograficos/datos_demograficos.json', orient='records', indent=4, force_ascii=False)

# 3. Exportar como XML
# Sanitizar nombres de columnas para XML
nuevos_nombres = {col: sanitize_xml_name(col) for col in df.columns}
df_xml = df.rename(columns=nuevos_nombres)

# Construir XML manualmente para mayor control
xml_content = '<?xml version="1.0" encoding="UTF-8"?>\n<datos_demograficos>\n'

for _, row in df_xml.iterrows():
    xml_content += '  <registro>\n'
    for col_name, value in row.items():
        xml_content += f'    <{col_name}>'
        
        # Escapar caracteres especiales para XML
        if isinstance(value, str):
            value = value.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
        xml_content += str(value)
        
        xml_content += f'</{col_name}>\n'
    xml_content += '  </registro>\n'

xml_content += '</datos_demograficos>'

# Guardar XML con codificación UTF-8
with open(r'data/datos_demograficos/datos_demograficos.xml', 'w', encoding='utf-8') as xml_file:
    xml_file.write(xml_content)

print("Proceso completado exitosamente!")
print("Archivos generados en 'data/datos_demograficos':")
print("- datos_demograficos.csv")
print("- datos_demograficos.json")
print("- datos_demograficos.xml")
"
Ahora lo que yo quiero, es que el 'extractor.py' agregue las siguientes columnas al final del DataFrame
"
1. Promedio de alumno
2. Total de asistencias
3. Total de inasistencias
4. Porcentaje de asistencias
5. Casilla de riesgo de reprobación (True o False dependiendo de la asistencia <70% y promedio <6)
"
DAME EL CODIGO COMPLETO SIN OMITIR NI UNA SOLA LINEA DE CODIGO